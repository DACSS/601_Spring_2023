{
  "hash": "0ec56f864f04b0eb8100dafd56691789",
  "result": {
    "markdown": "---\ntitle: \"Challenge 6 Solutions\"\nauthor: \"Meredith Rolfe & Sean Conway & Erico Yu\"\ndescription: \"Visualizing Time and Relationships\"\ndate: \"04/05/2023\"\nformat:\n  html:\n    toc: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_6\n  - solution\n  - hotel_bookings\n  - air_bnb\n  - fed_rate\n  - debt\n  - usa_hh\n  - abc_poll\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(here)\n\nsource(here(\"posts\",\"umass_colors.R\"))\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1)  create at least one graph including time (evolution)\n   - try to make them \"publication\" ready (optional)\n   - Explain why you choose the specific graph type\n2)  Create at least one graph depicting part-whole or flow relationships\n   - try to make them \"publication\" ready (optional)\n   - Explain why you choose the specific graph type\n\n:::{.panel-tabset}\n\n## Debt ⭐\n\nThis data set runs from the first quarter of 2003 to the second quarter of 2021, and includes quarterly measures of the total amount of household debt associated with 6 different types of loans - mortgage,HE revolving, auto, credit card, student, and other - plus a total household debt including all 6 loan types. This is another fantastic macroeconomic data product from the New York Federal Reserve. See Challenge 4.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_orig<-here(\"posts\",\"_data\",\"debt_in_trillions.xlsx\") %>%\n  read_excel()\ndebt<-debt_orig%>%\n  mutate(date = parse_date_time(`Year and Quarter`, \n                           orders=\"yq\"))\n```\n:::\n\n\n### Time Dependent Visualization\n\nLets look at how debt changes over time.\n\n\n::: {.cell .column-page layout-ncol=\"2\"}\n\n```{.r .cell-code}\nggplot(debt, aes(x=date, y=Total)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![Change in Total Debt Over Time](challenge6_solutions_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(debt, aes(x=date, y=Total)) +\n  geom_point(size=.5) +\n  geom_line()+\n  scale_y_continuous(labels = scales::label_number(suffix = \" Trillion\"))\n```\n\n::: {.cell-output-display}\n![Change in Total Debt, v2](challenge6_solutions_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n### Visualizing Part-Whole Relationships\n\nOne thing to note is that it isn't easy to include multiple lines on a single graph, that is because our data are not pivoted. Here is an example of how pivoting into tidy format makes things super easy. \n\n\n::: {.cell .column-page layout-ncol=\"2\"}\n\n```{.r .cell-code}\numass_palette<-c(\"red\", \"green\", \"dark blue\", \"light blue\", \"orange\", \n                 \"yellow\")%>%\n                   map(., get_umass_color)%>%\n                   unlist(.)\n\ndebt_long<-debt%>%\n  pivot_longer(cols = Mortgage:Other,\n               names_to = \"Loan\", \n               values_to = \"total\")%>%\n  select(-Total)%>%\n  mutate(Loan = as.factor(Loan))\n\nggplot(debt_long, aes(x=date, y=total, color=Loan)) +\n  geom_point(size=.5) +\n  geom_line() +\n  theme(legend.position = \"right\") +\n  scale_y_continuous(labels = scales::label_number(suffix = \" Trillion\")) +\n  scale_colour_manual(values=umass_palette)\n```\n\n::: {.cell-output-display}\n![Change in Debt Over Time, by Debt Type (line)](challenge6_solutions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(debt_long, aes(x=date, y=total, fill=Loan)) +\n  geom_bar(position=\"stack\", stat=\"identity\") +\n  scale_y_continuous(labels = scales::label_number(suffix = \" Trillion\"))+\n  theme(legend.position = \"top\") +\n  guides(fill = guide_legend(nrow = 1)) +\n  scale_fill_manual(labels =\n                      str_replace(levels(debt_long$Loan), \" \", \"\\n\"),\n                      values=umass_palette)\n```\n\n::: {.cell-output-display}\n![Change in Debt Over Time, by Debt Type (stacked)](challenge6_solutions_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\nWhile the stacked chart might be easier to read in some respects, it is harder to follow individual trend lines. One solution is to reorder in order to preserve as much information as possible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_long<-debt_long%>%\n  mutate(Loan = fct_relevel(Loan, \"Mortgage\", \"HE Revolving\",\n                            \"Auto Loan\", \"Student Loan\",  \n                            \"Credit Card\",\"Other\"))\n\nggplot(debt_long, aes(x=date, y=total, fill=Loan)) +\n  geom_bar(position=\"stack\", stat=\"identity\") +\n  scale_y_continuous(labels = scales::label_number(suffix = \" Trillion\"))+\n  theme(legend.position = \"top\") +\n  guides(fill = guide_legend(nrow = 1)) +\n  scale_fill_manual(labels=\n                      str_replace(levels(debt_long$Loan), \" \", \"\\n\"),\n                      values=umass_palette)\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n## Fed Rates ⭐⭐\n\nThis data set runs from July 1954 to March 2017, and includes daily macroeconomic indicators related to the effective federal funds rate - or the interest rate at which banks lend money to each other in order to meet mandated reserve requirements. There are 7 variables besides the date: 4 values related to the federal funds rate (*target*, *upper target*, *lower target*, and *effective*), 3 are related macroeconomic indicators (*inflation*, *GDP change*, and *unemployment rate*.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfed_rates_vars<-here(\"posts\",\"_data\",\"FedFundsRate.csv\") %>% \n  read_csv(n_max = 1,\n           col_names = NULL)%>%\n  select(-c(X1:X3))%>%\n  unlist(.)\n\nnames(fed_rates_vars) <-c(\"fed_target\", \"fed_target_upper\",\n                         \"fed_target_lower\", \"fed_effective\",\n                         \"gdp_ch\", \"unemploy\", \"inflation\")\n      \nfed_rates_orig<-here(\"posts\",\"_data\",\"FedFundsRate.csv\") %>% \n  read_csv(skip=1,\n           col_names = c(\"Year\", \"Month\", \"Day\", \n                         names(fed_rates_vars)))\n\nfed_rates<-fed_rates_orig%>%\n  mutate(date = make_date(Year, Month, Day))%>%\n  select(-c(Year, Month, Day))\n\nfed_rates <- fed_rates%>%\n  pivot_longer(cols=-date, \n               names_to = \"variable\",\n               values_to = \"value\")\n```\n:::\n\nNow we can try to visualize the data over time, with care paid to missing data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfed_rates%>%\n  filter(str_starts(variable, \"fed\"))%>%\nggplot(., aes(x=date, y=value, color=variable))+\n  geom_point(size=0)+\n  geom_line()+\n  scale_y_continuous(labels = scales::label_percent(scale = 1))\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWe can now see how closely the effective rate adheres to the target rate (and can see how the Fed changed the way it set it target rate around the time of the 2009 financial crash). Can we find out more by comparing the effective rate to one of the other macroeconomic indicators?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfed_rates%>%\n  filter(variable%in%c(\"fed_effective\", \"gdp_ch\", \n                       \"unemploy\", \"inflation\"))%>%\nggplot(., aes(x=date, y=value, color=variable))+\n  geom_point(size=0)+\n  geom_line()+\n  facet_grid(rows = vars(variable))\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyear_unemploy <- fed_rates %>%\n  pivot_wider(names_from = variable, values_from = value) %>%\n  mutate(year=year(date)) %>%\n  group_by(year) %>%\n  summarise(median_rate=median(unemploy)/100) %>%\n  ungroup()\nyear_unemploy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 64 × 2\n    year median_rate\n   <dbl>       <dbl>\n 1  1954      0.0575\n 2  1955      0.0425\n 3  1956      0.0415\n 4  1957      0.042 \n 5  1958      0.069 \n 6  1959      0.054 \n 7  1960      0.0545\n 8  1961      0.068 \n 9  1962      0.0555\n10  1963      0.0565\n# … with 54 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyear_unemploy %>%\n  ggplot(aes(year,median_rate))+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nyear_unemploy %>%\n  filter(year<=1981) %>%\n  ggplot(aes(year,median_rate))+\n  geom_line()+\n  scale_y_continuous(labels=scales::percent_format(),limits=c(0,.1))+\n  scale_x_continuous(breaks=seq(1955,1980,5))\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  labs(x=\"year\",y=\"median unemployment rate\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$x\n[1] \"year\"\n\n$y\n[1] \"median unemployment rate\"\n\nattr(,\"class\")\n[1] \"labels\"\n```\n:::\n:::\n\n\n## usa_hh ⭐⭐⭐\n\n\n::: {.cell}\n\n```{.r .cell-code}\nincome_brackets <- c(i1 = \"Under $15,000\",\n                     i2 = \"$15,000 to $24,999\",\n                     i3 = \"$25,000 to $34,999\",\n                     i4= \"$35,000 to $49,999\",\n                     i5 = \"$50,000 to $74,999\",\n                     i6 = \"$75,000 to $99,999\",\n                     i7 = \"$100,000 to $149,999\",\n                     i8 = \"$150,000 to $199,999\",\n                     i9 = \"$200,000 and over\")\n\nushh_orig <- here(\"posts\",\"_data\",\"USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\") %>%\n  read_excel(skip=5,\n         n_max = 352,\n         col_names = c(\"year\", \"hholds\", \"del\",\n                       str_c(\"income\",1:9,sep=\"_i\"),\n                       \"median_inc\", \"median_se\", \n                       \"mean_inc\",\"mean_se\"))%>%\n  select(-del)\nushh_orig \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 352 × 15\n   year   hholds incom…¹ incom…² incom…³ incom…⁴ incom…⁵ incom…⁶ incom…⁷ incom…⁸\n   <chr>  <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 ALL R… <NA>      NA      NA      NA      NA      NA      NA      NA      NA  \n 2 2019   128451     9.1     8       8.3    11.7    16.5    12.3    15.5     8.3\n 3 2018   128579    10.1     8.8     8.7    12      17      12.5    15       7.2\n 4 2017 2 127669    10       9.1     9.2    12      16.4    12.4    14.7     7.3\n 5 2017   127586    10.1     9.1     9.2    11.9    16.3    12.6    14.8     7.5\n 6 2016   126224    10.4     9       9.2    12.3    16.7    12.2    15       7.2\n 7 2015   125819    10.6    10       9.6    12.1    16.1    12.4    14.9     7.1\n 8 2014   124587    11.4    10.5     9.6    12.6    16.4    12.1    14       6.6\n 9 2013 3 123931    11.4    10.3     9.5    12.5    16.8    12      13.9     6.7\n10 2013 4 122952    11.3    10.4     9.7    13.1    17      12.5    13.6     6.3\n# … with 342 more rows, 5 more variables: income_i9 <dbl>, median_inc <dbl>,\n#   median_se <dbl>, mean_inc <chr>, mean_se <chr>, and abbreviated variable\n#   names ¹​income_i1, ²​income_i2, ³​income_i3, ⁴​income_i4, ⁵​income_i5,\n#   ⁶​income_i6, ⁷​income_i7, ⁸​income_i8\n```\n:::\n\n```{.r .cell-code}\nushh_id<-ushh_orig%>%\n  mutate(identity = case_when(\n    str_detect(year, \"[[:alpha:]]\") ~ year,\n    TRUE ~ NA_character_\n  ))%>%\n  fill(identity)%>%\n  filter(!str_detect(year, \"[[:alpha:]]\"))\n\nushh_id<-ushh_id%>%\n  separate(year, into=c(\"year\", \"delete\"), sep=\" \")%>%\n  mutate(identity = str_remove(identity, \" [0-9]+\"),\n         across(any_of(c(\"hholds\", \"mean_inc\", \"mean_se\", \"year\")), \n                as.numeric))%>%\n  select(-delete)\n\nushh_id\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 340 × 16\n    year hholds income…¹ incom…² incom…³ incom…⁴ incom…⁵ incom…⁶ incom…⁷ incom…⁸\n   <dbl>  <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  2019 128451      9.1     8       8.3    11.7    16.5    12.3    15.5     8.3\n 2  2018 128579     10.1     8.8     8.7    12      17      12.5    15       7.2\n 3  2017 127669     10       9.1     9.2    12      16.4    12.4    14.7     7.3\n 4  2017 127586     10.1     9.1     9.2    11.9    16.3    12.6    14.8     7.5\n 5  2016 126224     10.4     9       9.2    12.3    16.7    12.2    15       7.2\n 6  2015 125819     10.6    10       9.6    12.1    16.1    12.4    14.9     7.1\n 7  2014 124587     11.4    10.5     9.6    12.6    16.4    12.1    14       6.6\n 8  2013 123931     11.4    10.3     9.5    12.5    16.8    12      13.9     6.7\n 9  2013 122952     11.3    10.4     9.7    13.1    17      12.5    13.6     6.3\n10  2012 122459     11.4    10.6    10.1    12.5    17.4    12      13.9     6.3\n# … with 330 more rows, 6 more variables: income_i9 <dbl>, median_inc <dbl>,\n#   median_se <dbl>, mean_inc <dbl>, mean_se <dbl>, identity <chr>, and\n#   abbreviated variable names ¹​income_i1, ²​income_i2, ³​income_i3, ⁴​income_i4,\n#   ⁵​income_i5, ⁶​income_i6, ⁷​income_i7, ⁸​income_i8\n```\n:::\n\n```{.r .cell-code}\nushh <-ushh_id%>%\n  mutate(gp_identity = case_when(\n   identity %in% c(\"BLACK\", \"BLACK ALONE\") ~ \"gp_black\",\n    identity %in% c(\"ASIAN ALONE OR IN COMBINATION\",\n                  \"ASIAN AND PACIFIC ISLANDER\") ~ \"gp_asian\",\n    identity %in% c(\"WHITE, NOT HISPANIC\", \n                    \"WHITE ALONE, NOT HISPANIC\") ~ \"gp_white\",\n    identity %in% c(\"HISPANIC (ANY RACE)\") ~ \"gp_hisp\",\n    identity %in% c(\"ALL RACES\") ~ \"gp_all\"\n  ))%>%\n  filter(!is.na(gp_identity))%>%\n  group_by(year, gp_identity)%>%\n  summarise(across(c(starts_with(\"inc\"),starts_with(\"me\"),\n                     \"hholds\"), \n                   ~median(.x, na.rm=TRUE)))%>% # sort of cheating - getting median of a median?\n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nushh %>%\n  filter(gp_identity==\"gp_all\") %>%\n  ggplot(aes(year,median_inc))+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nushh %>%\n  filter(gp_identity!=\"gp_all\") %>%\n  mutate(gp_identity=str_remove(gp_identity,\"gp_\"))%>%\n  ggplot(aes(year,median_inc,col=gp_identity))+\n  geom_line()+\n  scale_x_continuous(limits=c(min(ushh$year),max(ushh$year)),\n                     breaks=seq(min(ushh$year),max(ushh$year),by=10))+\n  scale_y_continuous(labels = scales::dollar_format())+\n  scale_color_discrete(name=\"identity\")+\n  labs(x=\"year\",y=\"median income\")\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## hotel_bookings ⭐⭐⭐⭐\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_orig<- here(\"posts\",\"_data\",\"hotel_bookings.csv\") %>%\n  read_csv()\nbookings<-bookings_orig%>%\n  mutate(date_arrival = str_c(arrival_date_day_of_month,\n                              arrival_date_month,\n                              arrival_date_year, sep=\"/\"),\n         date_arrival = dmy(date_arrival))%>%\n  select(-starts_with(\"arrival\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_cumul <- bookings %>%\n  group_by(date_arrival) %>%\n  summarise(n=n()) %>%\n  ungroup() %>%\n  mutate(n_cumul=cumsum(n))\nbookings_cumul\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 793 × 3\n   date_arrival     n n_cumul\n   <date>       <int>   <int>\n 1 2015-07-01     122     122\n 2 2015-07-02      93     215\n 3 2015-07-03      56     271\n 4 2015-07-04      88     359\n 5 2015-07-05      53     412\n 6 2015-07-06      75     487\n 7 2015-07-07      54     541\n 8 2015-07-08      69     610\n 9 2015-07-09      80     690\n10 2015-07-10      51     741\n# … with 783 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bookings_cumul, aes(date_arrival,n_cumul))+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_month_n <- bookings %>%\n  mutate(month=floor_date(date_arrival,unit=\"month\")) %>%\n  group_by(month) %>%\n  summarise(n=n()) %>%\n  ungroup()\n\nbookings_month_n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 26 × 2\n   month          n\n   <date>     <int>\n 1 2015-07-01  2776\n 2 2015-08-01  3889\n 3 2015-09-01  5114\n 4 2015-10-01  4957\n 5 2015-11-01  2340\n 6 2015-12-01  2920\n 7 2016-01-01  2248\n 8 2016-02-01  3891\n 9 2016-03-01  4824\n10 2016-04-01  5428\n# … with 16 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_month_n %>%\n  ggplot(aes(month,n))+\n  geom_line()+\n  scale_x_date(NULL, date_labels = \"%b %y\",breaks=\"2 months\")+\n  scale_y_continuous(limits=c(0,7000))+\n  labs(x=\"date\",y=\"number of bookings\")+\n  theme(axis.text.x=element_text(angle=90))\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_month_hotel_n <- bookings %>%\n  mutate(month=floor_date(date_arrival,unit=\"month\")) %>%\n  group_by(month, hotel) %>%\n  summarise(n=n()) %>%\n  ungroup()\nbookings_month_hotel_n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 52 × 3\n   month      hotel            n\n   <date>     <chr>        <int>\n 1 2015-07-01 City Hotel    1398\n 2 2015-07-01 Resort Hotel  1378\n 3 2015-08-01 City Hotel    2480\n 4 2015-08-01 Resort Hotel  1409\n 5 2015-09-01 City Hotel    3529\n 6 2015-09-01 Resort Hotel  1585\n 7 2015-10-01 City Hotel    3386\n 8 2015-10-01 Resort Hotel  1571\n 9 2015-11-01 City Hotel    1235\n10 2015-11-01 Resort Hotel  1105\n# … with 42 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbookings_month_hotel_n %>%\n  ggplot(aes(month,n,col=hotel))+\n  geom_line()+\n  scale_x_date(NULL, date_labels = \"%b %y\",breaks=\"2 months\")+\n  scale_y_continuous(limits=c(0,5000))+\n  labs(x=\"date\",y=\"number of bookings\")+\n  theme(axis.text.x=element_text(angle=90))\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## air_bnb  ⭐⭐⭐⭐⭐\n\n::: {.cell}\n\n```{.r .cell-code}\nairb <- here(\"posts\",\"_data\",\"AB_NYC_2019.csv\") %>%\n  read_csv()\n\n#reorder the columns and put host_id and name in the front\nexample<-subset(airb, select = c(1:11)) #just keep the first ten columns\nexample<-example[,c(3,4, 9,10, 1:2, 5:8, 11)] #reorder columns to move the room_type and price ahead to the 3rd and 4th columns\n```\n:::\n\n\nThis dataset contains geolocation data (longtitude and latitude of each property liste), which allows us to create a map of these properties. So let's plot the may by the types of proeprties and their price. Note the options that I add for labels, titles, and colors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(example, aes(longitude, latitude, size = price, color = room_type), group = neighbourhood_group) +\n  geom_point() +\n  labs (size = \"Price of Property\",\n        title = \"Map of Airbnb Properties in NYC by Price and Room Types\",\n    subtitle = \"the airbnb dataset (AB_NYC_2019.csv)\")\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\n  coord_quickmap()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ggproto object: Class CoordQuickmap, CoordCartesian, Coord, gg>\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  <ggproto object: Class CoordQuickmap, CoordCartesian, Coord, gg>\n```\n:::\n:::\n\nNote that this map does not draw the boundary of the New York City. To plot a map with boundaries, we will have to get the shape data and merge the shape data of different neighbours or neighbourhood_groups. One source you can check out that contains the shape data or shape files (including most major countries and the US States) is the ggplot2::map__data().\n\n\nLet's draw a part-whole relationship by showing different neighbourhood_groups within the sum of bookings of a specific type of room.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Bivariate Visualization(s)\nggplot(airb, aes(x=room_type, fill=neighbourhood_group)) +  # setting x-axis as the room_type variable; #filling each room type by a second variable, the neighbourdhood group the property locates in\n \n  geom_bar( ) + #option of barchart\n  labs(\n    x = \"Type of Rooms\",\n    y = \"Amount of Bookings\",\n    colour = \"Neighborhood Group\",\n    title = \"Bivariate Visualization: room_type + neighbourhood_group\",\n    subtitle = \"the airbnb dataset (AB_NYC_2019.csv)\"\n  )\n```\n\n::: {.cell-output-display}\n![](challenge6_solutions_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n:::\n",
    "supporting": [
      "challenge6_solutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}